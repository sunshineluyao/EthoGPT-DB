# EthoGPT-DB

## Overview

The `ChatGPT` folder contains datasets and a Jupyter Notebook that compare cultural indices derived from survey data with those generated by ChatGPT. These resources are used to analyze the alignment and differences between human survey responses and AI-generated responses across various cultural dimensions.

### Files

- **ChatGPT/EthoGPT_ChatGPT.ipynb**: A Jupyter Notebook that performs a comprehensive analysis using OpenAI's GPT-4 model to generate cultural indices based on survey questions. The notebook is structured into several parts:
  - **Part I: Setup and API Key Configuration**: Mounts Google Drive, sets up the working directory, installs necessary packages, and configures the OpenAI API key.
  - **Part II: Survey ChatGPT and Generate Culture Indices**: Queries GPT-4 with survey questions to generate responses, encodes and processes the responses to calculate cultural indices.
  - **Part III: Comparative Studies**: Compares the generated indices with existing survey data and visualizes the results using cultural maps and interactive plots.

- **ChatGPT_Comparatives.csv**: Contains comparative data for traditional vs. secular and survival vs. self-expression values for different countries. It includes both survey data and ChatGPT's responses, along with calculated differences.

- **ChatGPT_Comparatives_Region.csv**: Provides aggregated error metrics (MSE and MAE) for cultural values across different regions, helping to understand regional variations in the data.


These datasets and the accompanying notebook are crucial for understanding how AI models like ChatGPT perceive and replicate cultural values, and they provide insights into the potential biases and alignments in AI-generated content.

## Installation

### Creating a `requirements.txt` File

Create a `requirements.txt` file in the root directory of your project with the following content:

```
openai
pandas
tqdm
matplotlib
adjustText
plotly
```

### Setting Up a Virtual Environment

1. **Create a virtual environment**:
   ```bash
   python -m venv venv
   ```

2. **Activate the virtual environment**:
   - On Windows:
     ```bash
     venv\Scripts\activate
     ```
   - On macOS and Linux:
     ```bash
     source venv/bin/activate
     ```

3. **Install the required packages**:
   ```bash
   pip install -r requirements.txt
   ```

## Usage

### Running on Google Colab

1. Open your web browser and go to [Google Colab](https://colab.research.google.com/).
2. Click on "File" > "Upload Notebook" and select `ChatGPT/EthoGPT_ChatGPT.ipynb` from your local machine.
3. Follow the instructions in the notebook to mount your Google Drive and set up the environment.

### Running Locally

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/EthoGPT.git
   ```
2. Navigate to the project directory:
   ```bash
   cd EthoGPT
   ```
3. Activate the virtual environment (if not already activated):
   - On Windows:
     ```bash
     venv\Scripts\activate
     ```
   - On macOS and Linux:
     ```bash
     source venv/bin/activate
     ```
4. Open the Jupyter Notebook:
   ```bash
   jupyter notebook ChatGPT/EthoGPT_ChatGPT.ipynb
   ```
5. Follow the instructions in the notebook to set up the environment and run the analysis.

## Results

The analysis results in a series of cultural indices that are saved as CSV files. These indices are visualized in various plots, including the Inglehartâ€“Welzel World Cultural Map, to provide insights into cultural trends and differences.

For more detailed results, refer to the output cells in the Jupyter Notebook.

---

Feel free to contribute to this project by submitting issues or pull requests. For any questions, please contact [your email].